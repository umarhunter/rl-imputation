{
 "cells": [
  {
   "cell_type": "code",
   "id": "369c60a6-c375-4c0c-9a4e-824e579d54b4",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-08-08T03:27:59.970946Z",
     "start_time": "2024-08-08T03:27:59.968270Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import util.util as util\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "ba0c5cec-6a1b-42b4-a4e4-49ef30dca1c9",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-08-08T03:28:04.571562Z",
     "start_time": "2024-08-08T03:28:04.563216Z"
    }
   },
   "source": [
    "data_path = \"data/toy_dataset.csv\"\n",
    "df = pd.read_csv(data_path, na_values='?')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "527a8e7e-b161-41ba-8d5b-fed3a19037e6",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-08-08T03:28:18.170717Z",
     "start_time": "2024-08-08T03:28:18.167716Z"
    }
   },
   "source": [
    "# missingness_rates = np.linspace(0.1, 1, 10)\n",
    "# \n",
    "# for miss_rate in missingness_rates:\n",
    "#     df_with_missing = util.introduce_missingness(df, miss_rate)\n",
    "#     print(f'Missing Rate: {miss_rate}')\n",
    "#     print(df_with_missing.head())"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T04:43:21.216584Z",
     "start_time": "2024-08-08T04:43:20.018016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#%pip install ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "spambase = fetch_ucirepo(id=94) \n",
    "letter_recognition = fetch_ucirepo(id=59) \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "\n",
    "\n",
    "# data (as pandas dataframes) \n",
    "X = spambase.data.features \n",
    "y = spambase.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(spambase.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(spambase.variables) "
   ],
   "id": "ae17cd6fcf67e8ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 94, 'name': 'Spambase', 'repository_url': 'https://archive.ics.uci.edu/dataset/94/spambase', 'data_url': 'https://archive.ics.uci.edu/static/public/94/data.csv', 'abstract': 'Classifying Email as Spam or Non-Spam', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 4601, 'num_features': 57, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1999, 'last_updated': 'Mon Aug 28 2023', 'dataset_doi': '10.24432/C53G6X', 'creators': ['Mark Hopkins', 'Erik Reeber', 'George Forman', 'Jaap Suermondt'], 'intro_paper': None, 'additional_info': {'summary': 'The \"spam\" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...\\n\\nThe classification task for this dataset is to determine whether a given email is spam or not.\\n\\t\\nOur collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word \\'george\\' and the area code \\'650\\' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.\\n\\nFor background on spam: Cranor, Lorrie F., LaMacchia, Brian A.  Spam!, Communications of the ACM, 41(8):74-83, 1998.\\n\\nTypical performance is around ~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter. See also Hewlett-Packard Internal-only Technical Report. External version forthcoming. ', 'purpose': None, 'funded_by': None, 'instances_represent': 'Emails', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'The last column of \\'spambase.data\\' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail.  The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  For the statistical measures of each attribute, see the end of this file.  Here are the definitions of the attributes:\\r\\n\\r\\n48 continuous real [0,100] attributes of type word_freq_WORD \\r\\n= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.\\r\\n\\r\\n6 continuous real [0,100] attributes of type char_freq_CHAR] \\r\\n= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\\r\\n\\r\\n1 continuous real [1,...] attribute of type capital_run_length_average \\r\\n= average length of uninterrupted sequences of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_longest \\r\\n= length of longest uninterrupted sequence of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_total \\r\\n= sum of length of uninterrupted sequences of capital letters \\r\\n= total number of capital letters in the e-mail\\r\\n\\r\\n1 nominal {0,1} class attribute of type spam\\r\\n= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \\r\\n', 'citation': None}}\n",
      "                          name     role        type demographic  \\\n",
      "0               word_freq_make  Feature  Continuous        None   \n",
      "1            word_freq_address  Feature  Continuous        None   \n",
      "2                word_freq_all  Feature  Continuous        None   \n",
      "3                 word_freq_3d  Feature  Continuous        None   \n",
      "4                word_freq_our  Feature  Continuous        None   \n",
      "5               word_freq_over  Feature  Continuous        None   \n",
      "6             word_freq_remove  Feature  Continuous        None   \n",
      "7           word_freq_internet  Feature  Continuous        None   \n",
      "8              word_freq_order  Feature  Continuous        None   \n",
      "9               word_freq_mail  Feature  Continuous        None   \n",
      "10           word_freq_receive  Feature  Continuous        None   \n",
      "11              word_freq_will  Feature  Continuous        None   \n",
      "12            word_freq_people  Feature  Continuous        None   \n",
      "13            word_freq_report  Feature  Continuous        None   \n",
      "14         word_freq_addresses  Feature  Continuous        None   \n",
      "15              word_freq_free  Feature  Continuous        None   \n",
      "16          word_freq_business  Feature  Continuous        None   \n",
      "17             word_freq_email  Feature  Continuous        None   \n",
      "18               word_freq_you  Feature  Continuous        None   \n",
      "19            word_freq_credit  Feature  Continuous        None   \n",
      "20              word_freq_your  Feature  Continuous        None   \n",
      "21              word_freq_font  Feature  Continuous        None   \n",
      "22               word_freq_000  Feature  Continuous        None   \n",
      "23             word_freq_money  Feature  Continuous        None   \n",
      "24                word_freq_hp  Feature  Continuous        None   \n",
      "25               word_freq_hpl  Feature  Continuous        None   \n",
      "26            word_freq_george  Feature  Continuous        None   \n",
      "27               word_freq_650  Feature  Continuous        None   \n",
      "28               word_freq_lab  Feature  Continuous        None   \n",
      "29              word_freq_labs  Feature  Continuous        None   \n",
      "30            word_freq_telnet  Feature  Continuous        None   \n",
      "31               word_freq_857  Feature  Continuous        None   \n",
      "32              word_freq_data  Feature  Continuous        None   \n",
      "33               word_freq_415  Feature  Continuous        None   \n",
      "34                word_freq_85  Feature  Continuous        None   \n",
      "35        word_freq_technology  Feature  Continuous        None   \n",
      "36              word_freq_1999  Feature  Continuous        None   \n",
      "37             word_freq_parts  Feature  Continuous        None   \n",
      "38                word_freq_pm  Feature  Continuous        None   \n",
      "39            word_freq_direct  Feature  Continuous        None   \n",
      "40                word_freq_cs  Feature  Continuous        None   \n",
      "41           word_freq_meeting  Feature  Continuous        None   \n",
      "42          word_freq_original  Feature  Continuous        None   \n",
      "43           word_freq_project  Feature  Continuous        None   \n",
      "44                word_freq_re  Feature  Continuous        None   \n",
      "45               word_freq_edu  Feature  Continuous        None   \n",
      "46             word_freq_table  Feature  Continuous        None   \n",
      "47        word_freq_conference  Feature  Continuous        None   \n",
      "48                 char_freq_;  Feature  Continuous        None   \n",
      "49                 char_freq_(  Feature  Continuous        None   \n",
      "50                 char_freq_[  Feature  Continuous        None   \n",
      "51                 char_freq_!  Feature  Continuous        None   \n",
      "52                 char_freq_$  Feature  Continuous        None   \n",
      "53                 char_freq_#  Feature  Continuous        None   \n",
      "54  capital_run_length_average  Feature  Continuous        None   \n",
      "55  capital_run_length_longest  Feature  Continuous        None   \n",
      "56    capital_run_length_total  Feature  Continuous        None   \n",
      "57                       Class   Target      Binary        None   \n",
      "\n",
      "                 description units missing_values  \n",
      "0                       None  None             no  \n",
      "1                       None  None             no  \n",
      "2                       None  None             no  \n",
      "3                       None  None             no  \n",
      "4                       None  None             no  \n",
      "5                       None  None             no  \n",
      "6                       None  None             no  \n",
      "7                       None  None             no  \n",
      "8                       None  None             no  \n",
      "9                       None  None             no  \n",
      "10                      None  None             no  \n",
      "11                      None  None             no  \n",
      "12                      None  None             no  \n",
      "13                      None  None             no  \n",
      "14                      None  None             no  \n",
      "15                      None  None             no  \n",
      "16                      None  None             no  \n",
      "17                      None  None             no  \n",
      "18                      None  None             no  \n",
      "19                      None  None             no  \n",
      "20                      None  None             no  \n",
      "21                      None  None             no  \n",
      "22                      None  None             no  \n",
      "23                      None  None             no  \n",
      "24                      None  None             no  \n",
      "25                      None  None             no  \n",
      "26                      None  None             no  \n",
      "27                      None  None             no  \n",
      "28                      None  None             no  \n",
      "29                      None  None             no  \n",
      "30                      None  None             no  \n",
      "31                      None  None             no  \n",
      "32                      None  None             no  \n",
      "33                      None  None             no  \n",
      "34                      None  None             no  \n",
      "35                      None  None             no  \n",
      "36                      None  None             no  \n",
      "37                      None  None             no  \n",
      "38                      None  None             no  \n",
      "39                      None  None             no  \n",
      "40                      None  None             no  \n",
      "41                      None  None             no  \n",
      "42                      None  None             no  \n",
      "43                      None  None             no  \n",
      "44                      None  None             no  \n",
      "45                      None  None             no  \n",
      "46                      None  None             no  \n",
      "47                      None  None             no  \n",
      "48                      None  None             no  \n",
      "49                      None  None             no  \n",
      "50                      None  None             no  \n",
      "51                      None  None             no  \n",
      "52                      None  None             no  \n",
      "53                      None  None             no  \n",
      "54                      None  None             no  \n",
      "55                      None  None             no  \n",
      "56                      None  None             no  \n",
      "57  spam (1) or not spam (0)  None             no  \n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "1d1c32aa-d97e-496a-a2c8-6c9c4babb38d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-08-08T03:28:18.622021Z",
     "start_time": "2024-08-08T03:28:18.614535Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class ImputationEnvironment:\n",
    "    def __init__(self, incomplete_data, complete_data):\n",
    "        self.incomplete_data = incomplete_data\n",
    "        self.complete_data = complete_data\n",
    "        self.state = incomplete_data.copy()\n",
    "        self.missing_indices = np.argwhere(pd.isna(incomplete_data.values))\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = self.incomplete_data.copy()\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action, position):\n",
    "        row, col = position\n",
    "        self.state.iat[row, col] = action\n",
    "\n",
    "        reward = -abs(self.complete_data.iat[row, col] - action)\n",
    "        done = not pd.isna(self.state.values).any()\n",
    "        return self.state, reward, done\n",
    "\n",
    "    def get_possible_actions(self, col):\n",
    "        # Ensure col is an integer if it's a numpy int\n",
    "        if isinstance(col, np.int64):\n",
    "            col = int(col)\n",
    "\n",
    "        if isinstance(col, int):\n",
    "            if 0 <= col < len(self.complete_data.columns):\n",
    "                col_name = self.complete_data.columns[col]\n",
    "            else:\n",
    "                raise KeyError(f\"Column index {col} out of range\")\n",
    "        elif isinstance(col, str):\n",
    "            if col in self.complete_data.columns:\n",
    "                col_name = col\n",
    "            else:\n",
    "                raise KeyError(f\"Column name '{col}' not found in DataFrame\")\n",
    "        else:\n",
    "            raise TypeError(\"Column must be either an integer index or a string column name\")\n",
    "\n",
    "        return self.complete_data[col_name].dropna().unique()\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, env, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
    "        self.env = env\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.q_table = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    def choose_action(self, state, position):\n",
    "        state_key = (tuple(state.values.flatten()), tuple(position))\n",
    "        \n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(self.env.get_possible_actions(position[1]))\n",
    "        else:\n",
    "            col = position[1]\n",
    "            actions = self.env.get_possible_actions(col)\n",
    "            q_values = {a: self.q_table[state_key][a] for a in actions}\n",
    "            return max(q_values, key=q_values.get)\n",
    "\n",
    "    def learn(self, state, action, reward, next_state, position):\n",
    "        state_key = (tuple(state.values.flatten()), tuple(position))\n",
    "        next_state_key = (tuple(next_state.values.flatten()), tuple(position))\n",
    "\n",
    "        q_predict = self.q_table[state_key][action]\n",
    "        q_target = reward + self.gamma * max(self.q_table[next_state_key].values(), default=0)\n",
    "        self.q_table[state_key][action] += self.alpha * (q_target - q_predict)\n",
    "\n",
    "    def train(self, episodes=1000):\n",
    "        for _ in range(episodes):\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            while not done:\n",
    "                position = random.choice(self.env.missing_indices)\n",
    "                action = self.choose_action(state, position)\n",
    "                next_state, reward, done = self.env.step(action, position)\n",
    "                self.learn(state, action, reward, next_state, position)\n",
    "                state = next_state"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "00c43aff-591c-464a-bd53-614be4c594d2",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-08-08T03:28:20.216501Z",
     "start_time": "2024-08-08T03:28:20.210994Z"
    }
   },
   "source": [
    "# Load data and train the agent\n",
    "incomplete_data_path = 'data/toy_dataset_missing.csv'\n",
    "complete_data_path = 'data/toy_dataset.csv'\n",
    "\n",
    "incomplete_data = pd.read_csv(incomplete_data_path)\n",
    "complete_data = pd.read_csv(complete_data_path)\n",
    "\n",
    "incomplete_data.replace(\"?\", np.nan, inplace=True)\n",
    "complete_data.replace(\"?\", np.nan, inplace=True) # we shouldn't really have missing data here but wtvr"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "622f4e06-4ef5-4d97-8b39-e5f867afc944",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-08-08T03:28:22.606881Z",
     "start_time": "2024-08-08T03:28:22.603872Z"
    }
   },
   "source": [
    "print(complete_data.columns)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Col 1', 'Col 2', 'Col 3', 'Col 4'], dtype='object')\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "70e0ce27-5655-4db5-b82c-aa00ef595c06",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-08-08T04:05:03.530543Z",
     "start_time": "2024-08-08T03:28:26.253535Z"
    }
   },
   "source": [
    "#Optional: Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "incomplete_data = pd.DataFrame(scaler.fit_transform(incomplete_data), columns=incomplete_data.columns)\n",
    "complete_data = pd.DataFrame(scaler.transform(complete_data), columns=complete_data.columns)\n",
    "\n",
    "env = ImputationEnvironment(incomplete_data, complete_data)\n",
    "agent = QLearningAgent(env)\n",
    "\n",
    "agent.train(episodes=800000)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "1ca810de-6581-4cd1-8e04-d356992be29e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# # Example calls\n",
    "# col_index = 3  # Example of integer index\n",
    "# col_name = 'Col 4'  # Example of column name\n",
    "\n",
    "# actions_by_index = env.get_possible_actions(col_index)\n",
    "# actions_by_name = env.get_possible_actions(col_name)\n",
    "# print(actions_by_index)\n",
    "# print(actions_by_name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8581e3e1-e126-4da9-aa66-57723aaf792d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-08-08T04:05:03.564693Z",
     "start_time": "2024-08-08T04:05:03.538223Z"
    }
   },
   "source": [
    "# Imputed data\n",
    "qlearning_imputed_data = env.state\n",
    "print(qlearning_imputed_data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Col 1  Col 2  Col 3  Col 4\n",
      "0   0.17   0.26   0.57   1.00\n",
      "1   0.50   0.53   0.00   0.83\n",
      "2   0.83   0.00   0.57   0.83\n",
      "3   0.17   0.26   0.87   0.50\n",
      "4   1.00   0.53   0.57   0.67\n",
      "5   0.50   0.84   0.86   0.00\n",
      "6   0.85   0.26   0.17   0.83\n",
      "7   0.03   1.00   0.71   1.00\n",
      "8   0.17   0.13   0.86   0.83\n",
      "9   0.00   0.26   1.00   0.70\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "7cafe688-0b74-475e-8ce4-6649aa306043",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T03:30:53.113733Z",
     "start_time": "2024-08-10T00:52:45.047150Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import logging\n",
    "from collections import deque\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class ImputationEnvironment:\n",
    "    def __init__(self, incomplete_data, complete_data):\n",
    "        self.incomplete_data = incomplete_data\n",
    "        self.complete_data = complete_data\n",
    "        self.state = incomplete_data.copy()\n",
    "        self.missing_indices = np.argwhere(pd.isna(incomplete_data.values))\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.incomplete_data.copy()\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action, position):\n",
    "        row, col = position\n",
    "        self.state.iat[row, col] = action\n",
    "\n",
    "        reward = -abs(self.complete_data.iat[row, col] - action)\n",
    "        done = not pd.isna(self.state.values).any()\n",
    "        return self.state, reward, done\n",
    "\n",
    "    def get_possible_actions(self, col):\n",
    "        col = int(col)\n",
    "        if 0 <= col < len(self.complete_data.columns):\n",
    "            col_name = self.complete_data.columns[col]\n",
    "        else:\n",
    "            raise KeyError(f\"Column index {col} out of range\")\n",
    "\n",
    "        return self.complete_data[col_name].dropna().unique()\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, gamma=0.95, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995, learning_rate=0.001, batch_size=32, memory_size=2000):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        self.gamma = gamma    # discount rate\n",
    "        self.epsilon = epsilon  # exploration rate\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        hidden_size = 24\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(self.state_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, self.action_size)  # Output one Q-value per action\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action_index, reward, next_state, done, position_col_index):\n",
    "        self.memory.append((state, action_index, reward, next_state, done, position_col_index))\n",
    "\n",
    "    def act(self, state, position_col_index):\n",
    "        possible_actions = env.get_possible_actions(position_col_index)\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            action_index = random.randrange(len(possible_actions))\n",
    "        else:\n",
    "            state_tensor = torch.FloatTensor(state)\n",
    "            q_values = self.model(state_tensor)\n",
    "            action_index = torch.argmax(q_values).item()\n",
    "        return action_index, possible_actions[action_index]\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        for state, action_index, reward, next_state, done, position_col_index in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                next_state_tensor = torch.FloatTensor(next_state)\n",
    "                possible_next_actions = env.get_possible_actions(position_col_index)\n",
    "                next_q_values = self.model(next_state_tensor)\n",
    "                target = reward + self.gamma * torch.max(next_q_values).item()\n",
    "            \n",
    "            target_f = self.model(torch.FloatTensor(state))\n",
    "            target_value = target_f.clone().detach()\n",
    "            target_value[action_index] = target\n",
    "            loss = criterion(target_f, target_value)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_state_dict(torch.load(name))\n",
    "\n",
    "    def save(self, name):\n",
    "        torch.save(self.model.state_dict(), name)\n",
    "\n",
    "# Load data\n",
    "incomplete_data = pd.read_csv('data/toy_dataset_missing.csv')\n",
    "complete_data = pd.read_csv('data/toy_dataset.csv')\n",
    "\n",
    "incomplete_data.replace(\"?\", np.nan, inplace=True)\n",
    "complete_data.replace(\"?\", np.nan, inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "incomplete_data = pd.DataFrame(scaler.fit_transform(incomplete_data), columns=incomplete_data.columns)\n",
    "complete_data = pd.DataFrame(scaler.transform(complete_data), columns=complete_data.columns)\n",
    "\n",
    "# Setup environment and agent\n",
    "env = ImputationEnvironment(incomplete_data, complete_data)\n",
    "state_size = incomplete_data.size  # Use total size if flattening entire data\n",
    "\n",
    "# Assuming the maximum number of possible actions based on the column with the most unique values\n",
    "action_size = max(len(env.get_possible_actions(col)) for col in range(incomplete_data.shape[1]))\n",
    "\n",
    "agent = DQNAgent(state_size=state_size, action_size=action_size)\n",
    "\n",
    "# Train the agent\n",
    "EPISODES = 800000\n",
    "progress_interval = 1  # How often to log progress\n",
    "start_time = time.time()\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    state = env.reset()\n",
    "    state = state.values.flatten()\n",
    "    done = False\n",
    "    while not done:\n",
    "        position = random.choice(env.missing_indices)\n",
    "        position_col_index = position[1]  # Column index\n",
    "        action_index, action_value = agent.act(state, position_col_index)\n",
    "        next_state, reward, done = env.step(action_value, position)\n",
    "        next_state = next_state.values.flatten()\n",
    "        agent.remember(state, action_index, reward, next_state, done, position_col_index)\n",
    "        state = next_state\n",
    "    agent.replay()\n",
    "    \n",
    "     # Log progress every 'progress_interval' episodes\n",
    "    if (e + 1) % progress_interval == 0:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        estimated_total_time = (elapsed_time / (e + 1)) * EPISODES\n",
    "        estimated_remaining_time = estimated_total_time - elapsed_time\n",
    "\n",
    "        logging.info(f\"Episode {e + 1}/{EPISODES} completed.\")\n",
    "        logging.info(f\"Elapsed Time: {elapsed_time:.2f}s, Estimated Total Time: {estimated_total_time:.2f}s, Estimated Remaining Time: {estimated_remaining_time:.2f}s\")\n",
    "# Save the trained model\n",
    "agent.save(\"dqn_model.pth\")\n",
    "\n",
    "# Print the imputed data\n",
    "dqlearning_imputed_data = env.state"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 142\u001B[0m\n\u001B[0;32m    140\u001B[0m position \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39mchoice(env\u001B[38;5;241m.\u001B[39mmissing_indices)\n\u001B[0;32m    141\u001B[0m position_col_index \u001B[38;5;241m=\u001B[39m position[\u001B[38;5;241m1\u001B[39m]  \u001B[38;5;66;03m# Column index\u001B[39;00m\n\u001B[1;32m--> 142\u001B[0m action_index, action_value \u001B[38;5;241m=\u001B[39m \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mact\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mposition_col_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    143\u001B[0m next_state, reward, done \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(action_value, position)\n\u001B[0;32m    144\u001B[0m next_state \u001B[38;5;241m=\u001B[39m next_state\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mflatten()\n",
      "Cell \u001B[1;32mIn[4], line 73\u001B[0m, in \u001B[0;36mDQNAgent.act\u001B[1;34m(self, state, position_col_index)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     state_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mFloatTensor(state)\n\u001B[1;32m---> 73\u001B[0m     q_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m     action_index \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(q_values)\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m action_index, possible_actions[action_index]\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\rl-imputation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\rl-imputation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\rl-imputation\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 219\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\rl-imputation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\rl-imputation\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\rl-imputation\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T23:44:37.977003Z",
     "start_time": "2024-08-09T23:44:37.823282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(dqlearning_imputed_data)\n",
    "\n",
    "actual_data = complete_data  # Assuming this is the complete data loaded earlier\n"
   ],
   "id": "960171a3ca93caa0",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dqlearning_imputed_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdqlearning_imputed_data\u001B[49m)\n\u001B[0;32m      3\u001B[0m actual_data \u001B[38;5;241m=\u001B[39m complete_data  \u001B[38;5;66;03m# Assuming this is the complete data loaded earlier\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dqlearning_imputed_data' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T04:43:20.010590Z",
     "start_time": "2024-08-08T04:43:20.001949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Q-Learning Agent Imputed Data\")\n",
    "mae, rmse = util.calculate_errors(qlearning_imputed_data, actual_data)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse}\")"
   ],
   "id": "d50763576c65bd15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Learning Agent Imputed Data\n",
      "Mean Absolute Error (MAE): 0.04825\n",
      "Root Mean Square Error (RMSE): 0.1388074205509201\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T04:43:20.018016Z",
     "start_time": "2024-08-08T04:43:20.011593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"DQNAgent Imputed Data\")\n",
    "mae,rmse = util.calculate_errors(dqlearning_imputed_data, actual_data)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse}\")"
   ],
   "id": "2fe5e1f54e4ac88c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQNAgent Imputed Data\n",
      "Mean Absolute Error (MAE): 0.05225\n",
      "Root Mean Square Error (RMSE): 0.15542683166043111\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b64d13d2bf265550"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python rl-imputation",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
