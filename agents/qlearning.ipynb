{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T03:36:26.452630Z",
     "start_time": "2024-10-31T03:36:24.665566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo, list_available_datasets\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configure logging to write to both console and file\n",
    "log_filename = \"training.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),  # Output to console\n",
    "        logging.FileHandler(log_filename, mode='w')  # Output to file\n",
    "    ]\n",
    ")\n",
    "\n",
    "def save_checkpoint(agent, episode, imputed_data, checkpoint_dir=\"checkpoints\"):\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    checkpoint = {\n",
    "        'q_table': dict(agent.q_table),\n",
    "        'episode': episode,\n",
    "        'epsilon': agent.epsilon\n",
    "    }\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_{episode}.pth\")\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    imputed_data_path = os.path.join(checkpoint_dir, f\"checkpoint_{episode}.csv\")\n",
    "    imputed_data.to_csv(imputed_data_path, index=False)\n",
    "    logging.info(f\"Checkpoint saved at episode {episode} with CSV file.\")\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_dir=\"checkpoints\", checkpoint_file=None):\n",
    "    if checkpoint_file is None:\n",
    "        checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.endswith(\".pth\")]\n",
    "        if not checkpoint_files:\n",
    "            return None\n",
    "        checkpoint_files.sort(key=lambda f: int(f.split('_')[1].split('.')[0]))\n",
    "        checkpoint_file = checkpoint_files[-1]\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, checkpoint_file)\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    logging.info(f\"Checkpoint loaded from {checkpoint_file}\")\n",
    "\n",
    "    # Convert q_table back to defaultdict\n",
    "    q_table = defaultdict(lambda: defaultdict(float), checkpoint['q_table'])\n",
    "    return {\n",
    "        'q_table': q_table,\n",
    "        'episode': checkpoint['episode'],\n",
    "        'epsilon': checkpoint['epsilon']\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_metrics(env, agent):\n",
    "    # Get the imputed data (after training)\n",
    "    imputed_data = env.state\n",
    "\n",
    "    # Check for NaN values before calculating MAE and RMSE\n",
    "    if imputed_data.isna().sum().sum() > 0:\n",
    "            # Option 1: Return a failure metric or log it\n",
    "        # return None, None\n",
    "        \n",
    "        # Option 2: Fill NaN values with mean (conservative fallback)\n",
    "        imputed_data = imputed_data.fillna(imputed_data.mean())\n",
    "\n",
    "    # Calculate MAE and RMSE between imputed data and complete data\n",
    "    mae = mean_absolute_error(env.complete_data.values.flatten(), imputed_data.values.flatten())\n",
    "    rmse = root_mean_squared_error(env.complete_data.values.flatten(), imputed_data.values.flatten())\n",
    "\n",
    "    return mae, rmse\n",
    "\n",
    "\n",
    "def get_toy_data():\n",
    "    # Sample Data\n",
    "    complete_data = pd.DataFrame({\n",
    "        'Col1': [1, 2, 3, 4],\n",
    "        'Col2': [4, 1, 2, 3],\n",
    "        'Col3': [1, 1, 1, 1],\n",
    "        'Col4': [2, 2, 3, 4]\n",
    "    })\n",
    "\n",
    "    incomplete_data = pd.DataFrame({\n",
    "        'Col1': [1, 2, np.nan, 4],\n",
    "        'Col2': [np.nan, 1, 2, 3],\n",
    "        'Col3': [1, np.nan, 1, 1],\n",
    "        'Col4': [2, 2, 3, np.nan]\n",
    "    })\n",
    "    return complete_data, incomplete_data\n",
    "\n",
    "def preprocess_columns_for_missing(df):\n",
    "    \"\"\"Preprocess columns by casting int64 columns to float64 to handle NaN values.\"\"\"\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_integer_dtype(df[col]):\n",
    "            df[col] = df[col].astype(np.float64)  # Convert int64 to float64\n",
    "    return df\n",
    "\n",
    "def generate_missing_df(df, missing_rate):\n",
    "    \"\"\"Introduce missing values randomly into the dataframe at the specified rate.\"\"\"\n",
    "    df_with_missing = preprocess_columns_for_missing(df)\n",
    "\n",
    "    # Total number of elements in the dataframe\n",
    "    total_elements = df_with_missing.size\n",
    "\n",
    "    # Number of elements to be set as NaN\n",
    "    num_missing = int(missing_rate * total_elements)\n",
    "\n",
    "    # Flatten the DataFrame to get flat indices\n",
    "    flat_indices = np.arange(total_elements)\n",
    "\n",
    "    # Get random indices\n",
    "    missing_indices = np.random.choice(flat_indices, num_missing, replace=False)\n",
    "\n",
    "    # Convert the flat indices to multi-dimensional indices\n",
    "    multi_dim_indices = np.unravel_index(missing_indices, df_with_missing.shape)\n",
    "\n",
    "    # Assign NaN to the missing indices\n",
    "    for row_idx, col_idx in zip(*multi_dim_indices):\n",
    "        df_with_missing.iat[row_idx, col_idx] = np.nan\n",
    "\n",
    "    return df_with_missing\n",
    "\n",
    "def load_dataset(datasetid, missing_rate):\n",
    "    dataset = fetch_ucirepo(id=datasetid)\n",
    "    df = dataset.data.original\n",
    "\n",
    "    # Drop the target columns before generating missing values\n",
    "    target_columns = dataset.metadata.target_col\n",
    "    logging.info(f\"Target columns: {target_columns}\")\n",
    "\n",
    "     # Ensure target_columns is valid\n",
    "    if target_columns and set(target_columns).issubset(df.columns):\n",
    "        df_dropped = df.drop(columns=target_columns)\n",
    "        logging.info(f\"Dropped target columns: {target_columns}\")\n",
    "    else:\n",
    "        logging.warning(f\"Target columns are missing or not valid for dataset {dataset_id}. Proceeding without dropping any columns.\")\n",
    "        df_dropped = df  # If no valid target columns, don't drop any columns\n",
    "\n",
    "    # Drop all non-numerical columns\n",
    "    df_numerical = df_dropped.select_dtypes(include=[np.number])\n",
    "    logging.info(f\"Retained numerical columns: {df_numerical.columns.tolist()}\")\n",
    "\n",
    "    # Use df_numerical as complete_data (without missing values)\n",
    "    complete_data = df_numerical.copy()\n",
    "\n",
    "    # Generate missing values for incomplete_data using the original copy of df_dropped\n",
    "    incomplete_data = generate_missing_df(df_dropped, missing_rate)  # Generate missing values for incomplete_data\n",
    "\n",
    "    # Ensure complete_data contains no missing values\n",
    "    complete_values_count = complete_data.isna().sum().sum()\n",
    "    logging.info(f\"The complete DataFrame contains {complete_values_count} missing values after load_dataset()\")\n",
    "\n",
    "    # Check if incomplete_data contains missing values\n",
    "    missing_values_count = incomplete_data.isna().sum().sum()\n",
    "    logging.info(f\"The incomplete DataFrame contains {missing_values_count} missing values after load_dataset()\")\n",
    "\n",
    "    # Return both the complete and incomplete datasets\n",
    "    return complete_data, incomplete_data\n",
    "\n",
    "\n",
    "class RLImputer:\n",
    "    def __init__(self, env, alpha=0.1, gamma=0.9, epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01):\n",
    "        logging.info(\"Initializing Q-Learning Agent\")\n",
    "        self.env = env\n",
    "        self.alpha = alpha # learning rate\n",
    "        self.gamma = gamma # discount factor\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "\n",
    "        # Simplified Q-table: store Q-values for positions and actions\n",
    "        self.q_table = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    def choose_action(self, position):\n",
    "        \"\"\"Choose an action using an epsilon-greedy policy.\"\"\"\n",
    "        state_key = tuple(position)  # Simplify state representation\n",
    "\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            action = random.choice(self.env.get_possible_actions(position[1]))\n",
    "            return action\n",
    "        else:\n",
    "            # Exploitation: choose the best known action\n",
    "            actions = self.env.get_possible_actions(position[1])\n",
    "            q_values = {a: self.q_table[state_key][a] for a in actions}\n",
    "            best_action = max(q_values, key=q_values.get)\n",
    "            return best_action\n",
    "\n",
    "    def learn(self, position, action, reward, next_position):\n",
    "        \"\"\"Update the Q-table based on the action taken.\"\"\"\n",
    "        state_key = tuple(position)\n",
    "        next_state_key = tuple(next_position)\n",
    "\n",
    "        q_predict = self.q_table[state_key][action]\n",
    "        q_target = reward + self.gamma * max(self.q_table[next_state_key].values(), default=0)\n",
    "        self.q_table[state_key][action] += self.alpha * (q_target - q_predict)\n",
    "\n",
    "    def train_with_logging(self, episodes=10000, log_interval=1000, results_dir=\"./results\",\n",
    "                                        experiment_table=None, progress_data=None, index=None):\n",
    "        start_episode = 1\n",
    "        # total_steps = 0  # Track the total number of steps (iterations)\n",
    "        max_steps_per_episode = 1000  # Limit for maximum steps per episode\n",
    "\n",
    "        try:\n",
    "            while start_episode <= episodes:\n",
    "                # Reset environment at the start of each episode\n",
    "                state = self.env.reset()\n",
    "                done = False\n",
    "                step = 0\n",
    "\n",
    "                # Loop over steps within an episode until done or max_steps_per_episode is reached\n",
    "                while not done and step < max_steps_per_episode:\n",
    "                    position = random.choice(self.env.missing_indices)\n",
    "                    action = self.choose_action(position)\n",
    "                    next_state, reward, done = self.env.step(action, position)\n",
    "                    self.learn(position, action, reward, next_state)\n",
    "                    state = next_state\n",
    "                    step += 1\n",
    "\n",
    "                # Decay epsilon\n",
    "                self.epsilon = max(self.epsilon * self.epsilon_decay, self.epsilon_min)\n",
    "\n",
    "                # Log at the end of each episode\n",
    "                if start_episode % log_interval == 0:\n",
    "                    logging.info(\n",
    "                        f\"Episode {start_episode} completed with {step} steps, epsilon={self.epsilon:.4f}\")\n",
    "                    # Calculate MAE and RMSE once the entire imputation is done\n",
    "                    mae, rmse = calculate_metrics(self.env, self)\n",
    "                    logging.info(f\"Final MAE = {mae:.6f}, Final RMSE = {rmse:.6f}\")\n",
    "\n",
    "                start_episode += 1\n",
    "\n",
    "            # Calculate MAE and RMSE once the entire imputation is done\n",
    "            mae, rmse = calculate_metrics(self.env, self)\n",
    "            logging.info(f\"Final MAE = {mae:.6f}, Final RMSE = {rmse:.6f}\")\n",
    "\n",
    "            # Update Streamlit table with MAE and RMSE at the end of all episodes\n",
    "            if experiment_table is not None and progress_data is not None:\n",
    "                progress_data.at[index, 'MAE'] = mae\n",
    "                progress_data.at[index, 'RMSE'] = rmse\n",
    "                experiment_table.dataframe(progress_data)\n",
    "\n",
    "            file_name = f\"{dataset_id}_missing_rate_{int(self.env.missing_rate * 100)}.csv\"\n",
    "            file_path = os.path.join(results_dir, file_name)\n",
    "            self.env.state.to_csv(file_path, index=False)\n",
    "            logging.info(f\"Final imputed data saved to {file_path}\")\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            logging.info(\"Training interrupted.\")\n",
    "\n",
    "\n",
    "class ImputationEnvironment:\n",
    "    def __init__(self, incomplete_data, complete_data, missing_rate):\n",
    "        self.incomplete_data = incomplete_data.copy()\n",
    "        self.complete_data = complete_data\n",
    "        self.state = incomplete_data.copy()\n",
    "        self.missing_indices = np.argwhere(pd.isna(self.incomplete_data.values))\n",
    "        self.missing_rate = missing_rate\n",
    "    def reset(self):\n",
    "        self.state = self.incomplete_data.copy()\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action, position):\n",
    "        row, col = position\n",
    "        self.state.iat[row, col] = action\n",
    "        reward = -abs(self.complete_data.iat[row, col] - action)\n",
    "        done = not pd.isna(self.state.values).any()\n",
    "        return self.state, reward, done\n",
    "\n",
    "    def get_possible_actions(self, col):\n",
    "        \"\"\"Return possible actions (values) for a column (excluding NaN).\"\"\"\n",
    "        return self.complete_data.iloc[:, col].dropna().unique()\n",
    "\n",
    "\n",
    "# Function to split dataset into training and test sets\n",
    "def split_dataset(complete_data, missing_rate, test_size=0.3, random_state=42):\n",
    "    complete_data_train, complete_data_test = train_test_split(complete_data, test_size=test_size,\n",
    "                                                               random_state=random_state)\n",
    "\n",
    "    # Generate missing values for both the training and test sets\n",
    "    incomplete_data_train = generate_missing_df(complete_data_train, missing_rate)\n",
    "    incomplete_data_test = generate_missing_df(complete_data_test, missing_rate)\n",
    "\n",
    "    return complete_data_train, incomplete_data_train, complete_data_test, incomplete_data_test"
   ],
   "id": "a92487133b8f8da0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Define a parameter grid (or sampler for random search)\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.05, 0.1, 0.5],\n",
    "    'gamma': [0.9, 0.91, 0.95, 0.99],\n",
    "    'epsilon': [1.0, 0.5, 0.1],\n",
    "    'epsilon_decay': [0.995, 0.99, 0.975]\n",
    "}\n",
    "\n",
    "# For random search, we define the number of samples to try\n",
    "n_iter_search = 10  # Number of random parameter combinations to try\n",
    "\n",
    "# Use ParameterSampler for random search\n",
    "random_search = list(ParameterSampler(param_grid, n_iter=n_iter_search, random_state=42))\n",
    "\n",
    "# Function to evaluate a single set of hyperparameters\n",
    "def evaluate_hyperparameters(params, train_env, test_env, episodes=10000):\n",
    "    # Initialize the RLImputer with current hyperparameters\n",
    "    agent = RLImputer(\n",
    "        env=train_env,\n",
    "        alpha=params['alpha'],\n",
    "        gamma=params['gamma'],\n",
    "        epsilon=params['epsilon'],\n",
    "        epsilon_decay=params['epsilon_decay']\n",
    "    )\n",
    "    \n",
    "    # Train the agent\n",
    "    agent.train_with_logging(episodes=episodes, log_interval=1000)\n",
    "    \n",
    "    # Test the agent on the test environment\n",
    "    test_env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        position = random.choice(test_env.missing_indices)\n",
    "        action = agent.choose_action(position)\n",
    "        _, _, done = test_env.step(action, position)\n",
    "\n",
    "    # Calculate MAE and RMSE\n",
    "    mae, rmse = calculate_metrics(test_env, agent)\n",
    "    \n",
    "    return mae, rmse\n",
    "\n",
    "# Store the best hyperparameters and results\n",
    "best_params = None\n",
    "best_mae = np.inf\n",
    "best_rmse = np.inf\n",
    "\n",
    "# Run random search for hyperparameter tuning\n",
    "for params in random_search:\n",
    "    logging.info(f\"Evaluating hyperparameters: {params}\")\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    complete_data_train, incomplete_data_train, complete_data_test, incomplete_data_test = split_dataset(complete_data, missing_rate)\n",
    "    train_env = ImputationEnvironment(incomplete_data_train, complete_data_train)\n",
    "    test_env = ImputationEnvironment(incomplete_data_test, complete_data_test)\n",
    "    \n",
    "    # Evaluate the agent with the current hyperparameters\n",
    "    mae, rmse = evaluate_hyperparameters(params, train_env, test_env)\n",
    "    \n",
    "    # Log and track the best results\n",
    "    logging.info(f\"MAE: {mae:.6f}, RMSE: {rmse:.6f} for hyperparameters: {params}\")\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_rmse = rmse\n",
    "        best_params = params\n",
    "\n",
    "# After tuning, log the best hyperparameters\n",
    "logging.info(f\"Best hyperparameters: {best_params} with MAE: {best_mae:.6f}, RMSE: {best_rmse:.6f}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "573e466b782a81a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Load dataset and create train/test splits using your existing function\n",
    "def prepare_test_data(dataset_id, missing_rate, random_state=42):\n",
    "    complete_data, _ = load_dataset(dataset_id, missing_rate)\n",
    "    complete_data_train, incomplete_data_train, complete_data_test, incomplete_data_test = split_dataset(\n",
    "        complete_data, missing_rate, test_size=0.3, random_state=random_state\n",
    "    )\n",
    "    return complete_data_test, incomplete_data_test\n",
    "\n",
    "# Load the final imputed data from your saved CSV\n",
    "def evaluate_on_test_set(dataset_id, missing_rate, final_imputed_path, random_state=42):\n",
    "    # Prepare test set\n",
    "    complete_data_test, _ = prepare_test_data(dataset_id, missing_rate, random_state)\n",
    "    \n",
    "    # Load final imputed results\n",
    "    final_imputed = pd.read_csv(final_imputed_path)\n",
    "    \n",
    "    # Flatten and calculate MAE/RMSE on test set\n",
    "    mae_test = mean_absolute_error(complete_data_test.values.flatten(), final_imputed.values.flatten())\n",
    "    rmse_test = mean_squared_error(complete_data_test.values.flatten(), final_imputed.values.flatten(), squared=False)\n",
    "    \n",
    "    print(f\"Test Set MAE: {mae_test}, RMSE: {rmse_test}\")\n",
    "    return mae_test, rmse_test\n",
    "\n",
    "# Usage\n",
    "dataset_id = 94\n",
    "missing_rate = 0.05\n",
    "final_imputed_path = './results/94_missing_rate_5.csv'\n",
    "evaluate_on_test_set(dataset_id, missing_rate, final_imputed_path)\n"
   ],
   "id": "ce6822e6fde39aaa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python rl-imputation",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
